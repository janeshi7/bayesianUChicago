---
title: "msca32014_hw8"
author: "Zhiyin Shi"
date: "May 23, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###1. Import Data
```{r}
dat = swiss

head(dat)
dim(dat)
```
Multiple Regression and Variable Selection.

###2 Questions
####2.1 Fit robust linear regression for response Fertility using all available predictors without shrinkage
```{r}
Ntot = nrow(dat)
y    = dat$Fertility
x    = as.matrix(dat[, -1])
Nx   = ncol(x)   

dataList = list(Ntotal = Ntot, y = y, x = x, Nx = Nx)

suppressWarnings(library(rstan))

modelString<-"
data {
    int<lower=1> Ntotal;
    int<lower=1> Nx;
    vector[Ntotal] y;
    matrix[Ntotal, Nx] x;
}
transformed data {
    real meanY;
    real sdY;
    vector[Ntotal] zy; // normalized
    vector[Nx] meanX;
    vector[Nx] sdX;
    matrix[Ntotal, Nx] zx; // normalized
    
    meanY = mean(y);
    sdY = sd(y);
    zy = (y - meanY) / sdY;
    for ( j in 1:Nx ) {
        meanX[j] = mean(x[,j]);
        sdX[j] = sd(x[,j]);
        for ( i in 1:Ntotal ) {
            zx[i,j] = ( x[i,j] - meanX[j] ) / sdX[j];
        }
    }
}
parameters {
    real zbeta0;
    vector[Nx] zbeta;
    real<lower=0> nu;
    real<lower=0> zsigma;
}
transformed parameters{
    vector[Ntotal] zy_hat;
    zy_hat = zbeta0 + zx * zbeta;
}
model {
    zbeta0 ~ normal(0, 2);
    zbeta  ~ normal(0, 2);
    nu ~ exponential(1/30.0);
    zsigma ~ uniform(1.0E-5 , 1.0E+1);
    zy ~ student_t(1+nu, zy_hat, zsigma);
}
generated quantities { 
    // Transform to original scale:
    real beta0; 
    vector[Nx] beta;
    real sigma;
    // .* and ./ are element-wise product and divide
    beta0 = zbeta0*sdY  + meanY - sdY * sum( zbeta .* meanX ./ sdX );
    beta = sdY * ( zbeta ./ sdX );
    sigma = zsigma * sdY;
} "

RobustMultipleRegressionDso = stan_model( model_code=modelString)

RegresNoShrink = sampling(RobustMultipleRegressionDso, data = dataList,
                          pars=c('beta0', 'beta', 'nu', 'sigma'),
                          iter=5000, chains = 3, cores = 2)

#Check for convergence
stan_trace(RegresNoShrink)
stan_ac(RegresNoShrink)

#Analyze the parameter estimates
summary(RegresNoShrink)$summary[, c(1, 3, 4, 8, 9)]
pairs(RegresNoShrink ,pars=c("beta0","beta[1]","beta[2]", "beta[3]", 
                             "beta[4]", "beta[5]"))
plot(RegresNoShrink)
```
**Q2.1.1 Analyze correlations between slope parameters and interpret them.**\
Parameter beta0 is strongly negative corelated with beta1, beta2 and beta5. beta1 is also strongly positive corelated with beta2, beta2 and beta5 and moderately negative corelated with beta4. beta2 is strongly negative corelated with beta3 and strongly positive corelated with beta4. \
\
**Q2.1.2 Which slope parameters are not significant based on 95%-HDI?**\
95% HDI of beta2 contains zero, therefore is not significant.\
\
**Q2.1.3 Does the model satisfy Gaussian assumption?**\
The nu parameter has mean value 35.14 and lower bound of 95% HDI is 3.52. The mean nu value is large enough to conclude the Gaussian assumption is met, but the wide HDI intervals add uncertainity to the assumption.

####2.2 Fit robust linear regression for response Fertility using all available predictors with shrinkage
```{r}
modelString = "
data {
    int<lower=1> Ntotal;
    int<lower=1> Nx;
    vector[Ntotal] y;
    matrix[Ntotal, Nx] x;
}
transformed data {
    real meanY;
    real sdY;
    vector[Ntotal] zy; // normalized
    vector[Nx] meanX;
    vector[Nx] sdX;
    matrix[Ntotal, Nx] zx; // normalized
    
    meanY = mean(y);
    sdY = sd(y);
    zy = (y - meanY) / sdY;
    for ( j in 1:Nx ) {
        meanX[j] = mean(x[,j]);
        sdX[j] = sd(x[,j]);
        for ( i in 1:Ntotal ) {
            zx[i,j] = ( x[i,j] - meanX[j] ) / sdX[j];
        }
    }
}
parameters {
    real zbeta0;
    real<lower=0> sigmaBeta;
    vector[Nx] zbeta;
    real<lower=0> nu;
    real<lower=0> zsigma;
}
transformed parameters{
    vector[Ntotal] zy_hat;
    zy_hat = zbeta0 + zx * zbeta;
}
model {
    zbeta0 ~ normal(0, 2);
    sigmaBeta ~ gamma(1,5); // mode 0, sd 0.5
    zbeta  ~ student_t(1.0/30.0, 0, sigmaBeta);
    nu ~ exponential(1/30.0);
    zsigma ~ uniform(1.0E-5 , 1.0E+1);
    zy ~ student_t(1+nu, zy_hat, zsigma);
}
generated quantities { 
    // Transform to original scale:
    real beta0; 
    vector[Nx] beta;
    real sigma;
    // .* and ./ are element-wise product and divide
    beta0 = zbeta0*sdY  + meanY - sdY * sum( zbeta .* meanX ./ sdX );
    beta = sdY * ( zbeta ./ sdX );
    sigma = zsigma * sdY;
} "

RobustMultiRegShrinkDso = stan_model( model_code=modelString)

RegresShrink = sampling(RobustMultiRegShrinkDso, data = dataList,
                        pars=c('beta0', 'beta', 'nu', 'sigma'),
                        iter=5000, chains = 3, cores = 2)

#Check for convergence
stan_trace(RegresShrink)
stan_ac(RegresShrink)

#Analyze the parameter estimates
summary(RegresShrink)$summary[, c(1, 3, 4, 8, 9)]
pairs(RegresShrink ,pars=c("beta0","beta[1]","beta[2]", "beta[3]", 
                             "beta[4]", "beta[5]"))
plot(RegresShrink)

cbind(summary(RegresNoShrink)$summary[, c(1, 4, 8)], summary(RegresShrink)$summary[, c(1, 4, 8)])
```

**Q2.2.1 Modify parameters of prior distribution for sigmaBeta from values in the workshop in order to make shrinkage stronger**
In order to make shrinkage stronger, sigmaBeta is now drawn from gamma(1,5). The trace and autocorrelation plots demostrate convergence. This prior is so strong that all the six parameters are shrunk towards zero. beta4 is now very very close to zero.\
\
**Q2.2.2 Which parameters shrunk to become insignificant in model with shrinkage?**\
After shrinking, beta1, beta2 and beta4 are not significant.

####2.3 Run model selection like in Workshop 2
```{r}
suppressWarnings(library(runjags))

modelString = "
    # Standardize the data:
    data {
        ym <- mean(y)
        ysd <- sd(y)
        for ( i in 1:Ntotal ) {
            zy[i] <- ( y[i] - ym ) / ysd
        }
        for ( j in 1:Nx ) {
            xm[j]  <- mean(x[,j])
            xsd[j] <-   sd(x[,j])
            for ( i in 1:Ntotal ) {
                zx[i,j] <- ( x[i,j] - xm[j] ) / xsd[j]
            }
        }
    }
    # Specify the model for standardized data:
    model {
        for ( i in 1:Ntotal ) {
            zy[i] ~ dt( zbeta0 + sum( delta[1:Nx] * zbeta[1:Nx] * zx[i,1:Nx] ) ,  1/zsigma^2 , nu )
        }
        # Priors vague on standardized scale:
        zbeta0 ~ dnorm( 0 , 1/2^2 )
        for ( j in 1:Nx ) {
            zbeta[j] ~ dt( 0 , 1/sigmaBeta^2 , 1 ) 
            delta[j] ~ dbern( 0.5 )
        }
        zsigma ~ dunif( 1.0E-5 , 1.0E+1 )
        ## Uncomment one of the following specifications for sigmaBeta:
        # sigmaBeta <- 2.0
        # sigmaBeta ~ dunif( 1.0E-5 , 1.0E+2 )
        sigmaBeta ~ dgamma(1.1051,0.1051) # mode 1.0, sd 10.0
        # sigmaBeta <- 1/sqrt(tauBeta) ; tauBeta ~ dgamma(0.001,0.001) 
        nu ~ dexp(1/30.0)
        # Transform to original scale:
        beta[1:Nx] <- ( delta[1:Nx] * zbeta[1:Nx] / xsd[1:Nx] )*ysd
        beta0 <- zbeta0*ysd  + ym - sum( delta[1:Nx] * zbeta[1:Nx] * xm[1:Nx] / xsd[1:Nx] )*ysd
        sigma <- zsigma*ysd
    }
"
parameters    = c("beta0",  "beta",  "sigma", "delta", "sigmaBeta", 
                  "zbeta0", "zbeta", "zsigma", "nu" )
adaptSteps    = 500
burnInSteps   = 1000
numSavedSteps = 15000
thinSteps     = 25
nChains       = 3
runjagsMethod = "parallel"  # change to "rjags" in case of working on 1-core cpu 
# run JAGS
varSelect <- run.jags(method=runjagsMethod,
                       model=modelString, 
                       monitor=parameters, 
                       data=dataList,
                       n.chains=nChains,
                       adapt=adaptSteps,
                       burnin=burnInSteps, 
                       sample=ceiling(numSavedSteps/nChains),
                       thin=thinSteps,
                       summarise=FALSE,
                       plots=FALSE)

summary(varSelect)

trajectoriesDelta = as.matrix(varSelect$mcmc[,8:12])
Nchain = nrow(trajectoriesDelta)
head(trajectoriesDelta)
```

**Q2.3.1 Order predictors using their inclusion probabilities as a measure of relative importance**
```{r}
(inclAgr = sum(trajectoriesDelta[,1]==1)/Nchain) #Agriculture
(inclExm = sum(trajectoriesDelta[,2]==1)/Nchain) #Examination
(inclEdu = sum(trajectoriesDelta[,3]==1)/Nchain) #Education
(inclCath= sum(trajectoriesDelta[,4]==1)/Nchain) #Catholic
(inclMort= sum(trajectoriesDelta[,5]==1)/Nchain) #Infant.Mortality
```
**Answer:** Using 0.5 as a threshold, Education, Catholic and Infant.Mortality are included in about 90% of mcmc and agriculture in 57% of the time. Therefore they are significant. Examination has an inclusion rate of 0.34 which is not significant and Ariculture just passed our baseline.\
\
**Q2.3.2 Compare relevance of the following sub-models based on their observed frequencies:**\
1. Fertility~Agriculture+Examination\
2. Fertility~Education+Catholic+Infant.Mortality\
3. Fertility~Agriculture+Education+Catholic+Infant.Mortality\
4. Fertility~.\
```{r}
(configAgrExm = sum(apply(trajectoriesDelta,1,function(z) 
  prod(z==c(1,1,0,0,0))))/Nchain)

(configEduCathMort = sum(apply(trajectoriesDelta,1,function(z) 
  prod(z==c(0,0,1,1,1))))/Nchain)

(configAgrEduCathMort = sum(apply(trajectoriesDelta,1,function(z) 
  prod(z==c(1,0,1,1,1))))/Nchain)

(configAll = sum(apply(trajectoriesDelta,1,function(z) 
  prod(z==c(1,1,1,1,1))))/Nchain)
```
**Answer:** 1 is extremly infrequent. 2 appears 26% of the time. Full model only appears 16.6% of the time. The most frequently observed model is 3, with rate of 30.8%.